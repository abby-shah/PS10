---
title: "STAT/MATH 495: Problem Set 10"
author: "Syed Abbas Shah"
date: "2017-11-28"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE)
```



# Collaboration

Please indicate who you collaborated with on this assignment: 

No one

# Setup

```{r Setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
library(glmnet)
library(knitr)
library(MLmetrics)

train <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")

# Only use 150 observations to train model!
set.seed(76)
train <- train %>% 
  mutate(log_price_doc = log(price_doc)) %>% 
  sample_n(150)

# Need "dummy" outcome variable to make model.matrix() code below work
test <- test %>% 
  mutate(log_price_doc=1) 

# Model formula
model_formula <- as.formula("log_price_doc ~ full_sq + area_m + raion_popul + green_zone_part + indust_part + children_preschool + preschool_education_centers_raion + children_school + school_education_centers_raion + school_education_centers_top_20_raion + healthcare_centers_raion + university_top_20_raion + sport_objects_raion + additional_education_raion + culture_objects_top_25 + culture_objects_top_25_raion + shopping_centers_raion + office_raion + thermal_power_plant_raion + incineration_raion + oil_chemistry_raion + radiation_raion + railroad_terminal_raion + big_market_raion + nuclear_reactor_raion + detention_facility_raion + full_all + male_f + female_f + young_all + young_male + young_female + work_all + work_male + work_female + ekder_all + ekder_male + ekder_female + ID_metro + metro_min_avto + metro_km_avto + kindergarten_km + school_km + park_km + green_zone_km + industrial_km + water_treatment_km + cemetery_km + incineration_km + railroad_station_avto_km + railroad_station_avto_min + ID_railroad_station_avto + public_transport_station_km + public_transport_station_min_walk + water_km + water_1line + mkad_km + ttk_km + sadovoe_km + bulvar_ring_km + kremlin_km + big_road1_km + ID_big_road1 + big_road1_1line + big_road2_km + ID_big_road2 + railroad_km + railroad_1line + zd_vokzaly_avto_km + ID_railroad_terminal + bus_terminal_avto_km + ID_bus_terminal + oil_chemistry_km + nuclear_reactor_km + radiation_km + power_transmission_line_km + thermal_power_plant_km + ts_km + big_market_km + market_shop_km + fitness_km + swim_pool_km + ice_rink_km + stadium_km + basketball_km + hospice_morgue_km + detention_facility_km + public_healthcare_km + university_km + workplaces_km + shopping_centers_km + office_km + additional_education_km + preschool_km + big_church_km + church_synagogue_km + mosque_km + theater_km + museum_km + exhibition_km + catering_km + green_part_500 + prom_part_500 + office_count_500 + office_sqm_500 + trc_count_500 + trc_sqm_500") 

# Define predictor matrices
predictor_matrix_train <- model.matrix(model_formula, data = train)[, -1]
predictor_matrix_test <- model.matrix(model_formula, data = test)[, -1]
```


# My Work

##LM Model

First, let's fit the LM Model.

```{r LM Model, message=FALSE, warning=FALSE}
model_lm <- lm(model_formula, data=train)

#Regression table in tidy format
model_lm %>% 
  broom::glance()

#TRAIN ERROR
y_hat <- predict(model_lm, newdata=train)
lm_train_rmsle <- MLmetrics::RMSLE(exp(y_hat), train$price_doc)

#PREDICTIONS
y_hat <- predict(model_lm, newdata=test)
test$log_price_doc<-y_hat
test$price_doc <- exp(test$log_price_doc)
sample_submission$price_doc <- test$price_doc
write_excel_csv(sample_submission, "submission1")
```



##LASSO

Now, Let's try the LASSO Model.
```{r LASSO, message=FALSE, warning=FALSE}
lambda_inputs <- 10^seq(-2, 10, length = 100)
LASSO_fit <- glmnet(x=predictor_matrix_train, y=train$log_price_doc, alpha = 1, lambda = lambda_inputs)
LASSO_CV <- cv.glmnet(x=predictor_matrix_train, y=train$log_price_doc, alpha=1, lambda=lambda_inputs)

# Optimal lambdas
lambda_star <- LASSO_CV$lambda.min
lambda_star_1SE <- LASSO_CV$lambda.1se
plot(LASSO_CV)
abline(v=log(lambda_star), col="red")
abline(v=log(lambda_star_1SE), col="blue")

#TRAIN error

y_hat_train <- predict(LASSO_fit, newx=predictor_matrix_train, s=lambda_star_1SE) %>% 
  as.vector()
lasso_train_rmsle <- MLmetrics::RMSLE(exp(y_hat_train), train$price_doc)

#Predictions
y_hat <- predict(LASSO_fit, newx=predictor_matrix_test, s=lambda_star_1SE) %>% 
  as.vector()
hist(y_hat)
sample_submission$price_doc<- exp(y_hat)
write_excel_csv(sample_submission, "submission2")
```




# Scoreboard

Using the "scoring mechanism" for the Russian Housing Kaggle competition, fill
in these cells:

```{r}
kaggle_lm <- 2.63413
kaggle_lasso<- .42577
Method<- c("LM", "LASSO crossvalidated")
`Training Score` <- c(round(lm_train_rmsle,5), round(lasso_train_rmsle,5)) 
`Kaggle Score` <- c(kaggle_lm, kaggle_lasso)
scores <- cbind(Method, `Training Score`, `Kaggle Score`)
kable(scores, format="markdown", caption ="Scores")
```



# Analysis

The Kaggle Score for the Lm model is unsurprisingly higher than that of the LASSO model. Apart from being less optimal than LASSO, the fact that we use very few observations to train our model probably also impacts its effectiveness. 

The Kaggle Score for the LASSO model with a cross-validated optimal lambda is much lower, indicating that the LASSO model is much better at predicting the test data than the simple lm model.